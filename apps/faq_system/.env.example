# FAQ System 専用 .env（apps/faq_system/main.py で自動ロード）
# ルート .env より優先されます。

# --- LLM（必ず 1 つを選ぶ） ---
# openai / ollama / anthropic / google / deepseek / mock
LLM_PROVIDER=ollama

# OpenAI を使う場合（LLM_PROVIDER=openai）
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Ollama を使う場合（LLM_PROVIDER=ollama）
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# WSL から Windows 側 Ollama を使う場合の例
# OLLAMA_BASE_URL=http://host.docker.internal:11434
# または OLLAMA_BASE_URL=http://<windows-host-ip>:11434

# --- AgentFlow 共通設定の FAQ 上書き（必要時のみ） ---
# SUPABASE_URL=
# QDRANT_URL=
# CHROMA_PERSIST_DIR=./data/chroma
# CHROMA_COLLECTION=faq_knowledge

# --- FAQ アプリ固有 DB（認証/チャット履歴） ---
FAQ_DATABASE_URL=sqlite+aiosqlite:///./faq_system.db
FAQ_DB_AUTO_CREATE=true
FAQ_AUTH_PROVIDER=local_db

# --- FAQ 起動設定 ---
# app_config.json の ports.api が既定。通常は未設定でよい。
# FAQ_HOST=0.0.0.0
# FAQ_PORT=8005
