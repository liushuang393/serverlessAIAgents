"""ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹.

çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã¨å“è³ªã‚’å¯è¦–åŒ–ã€‚

æ©Ÿèƒ½:
- éƒ¨é–€/ãƒˆãƒ”ãƒƒã‚¯åˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸
- å‘½ä¸­ç‡çµ±è¨ˆ
- ã‚®ãƒ£ãƒƒãƒ—åˆ†æ

ä½¿ç”¨ä¾‹:
    >>> from apps.faq_system.backend.services import CoverageDashboard
    >>>
    >>> dashboard = CoverageDashboard()
    >>> report = await dashboard.get_coverage_report()
"""

from __future__ import annotations

import logging
from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any


logger = logging.getLogger(__name__)


class CoverageLevel(str, Enum):
    """ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒ™ãƒ«."""

    EXCELLENT = "excellent"  # >= 90%
    GOOD = "good"  # >= 70%
    FAIR = "fair"  # >= 50%
    POOR = "poor"  # < 50%


@dataclass
class QueryLog:
    """ã‚¯ã‚¨ãƒªãƒ­ã‚°.

    Attributes:
        query_id: ã‚¯ã‚¨ãƒªID
        query_text: ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆ
        topic: ãƒˆãƒ”ãƒƒã‚¯
        department: éƒ¨é–€
        kb_type: KBã‚¿ã‚¤ãƒ—
        hit: å‘½ä¸­ã—ãŸã‹
        hit_count: å‘½ä¸­ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
        top_score: æœ€é«˜ã‚¹ã‚³ã‚¢
        created_at: ä½œæˆæ—¥æ™‚
    """

    query_id: str
    query_text: str
    topic: str = ""
    department: str = ""
    kb_type: str = ""
    hit: bool = False
    hit_count: int = 0
    top_score: float = 0.0
    response_time_ms: float = 0.0
    created_at: datetime = field(default_factory=datetime.now)
    user_id: str = ""


@dataclass
class CoverageStats:
    """ã‚«ãƒãƒ¬ãƒƒã‚¸çµ±è¨ˆ.

    Attributes:
        total_queries: ç·ã‚¯ã‚¨ãƒªæ•°
        hit_queries: å‘½ä¸­ã‚¯ã‚¨ãƒªæ•°
        miss_queries: ãƒŸã‚¹ã‚¯ã‚¨ãƒªæ•°
        hit_rate: å‘½ä¸­ç‡
        avg_hit_count: å¹³å‡å‘½ä¸­æ•°
        avg_top_score: å¹³å‡ãƒˆãƒƒãƒ—ã‚¹ã‚³ã‚¢
        avg_response_time_ms: å¹³å‡å¿œç­”æ™‚é–“
    """

    total_queries: int = 0
    hit_queries: int = 0
    miss_queries: int = 0
    hit_rate: float = 0.0
    avg_hit_count: float = 0.0
    avg_top_score: float = 0.0
    avg_response_time_ms: float = 0.0
    level: CoverageLevel = CoverageLevel.POOR


@dataclass
class TopicCoverage:
    """ãƒˆãƒ”ãƒƒã‚¯åˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸.

    Attributes:
        topic: ãƒˆãƒ”ãƒƒã‚¯
        stats: çµ±è¨ˆ
        sample_misses: ãƒŸã‚¹ã‚µãƒ³ãƒ—ãƒ«
        recommendations: æ¨å¥¨äº‹é …
    """

    topic: str
    stats: CoverageStats
    sample_misses: list[str] = field(default_factory=list)
    recommendations: list[str] = field(default_factory=list)
    trend: str = "stable"  # improving, stable, declining


@dataclass
class GapAnalysis:
    """ã‚®ãƒ£ãƒƒãƒ—åˆ†æ.

    Attributes:
        topic: ãƒˆãƒ”ãƒƒã‚¯
        query_count: ã‚¯ã‚¨ãƒªæ•°
        hit_rate: å‘½ä¸­ç‡
        severity: æ·±åˆ»åº¦
        sample_queries: ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒª
        suggested_content: ææ¡ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    """

    topic: str
    query_count: int
    hit_rate: float
    severity: str  # low, medium, high, critical
    sample_queries: list[str] = field(default_factory=list)
    suggested_content: list[str] = field(default_factory=list)


@dataclass
class CoverageReport:
    """ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆ.

    Attributes:
        overall: å…¨ä½“çµ±è¨ˆ
        by_topic: ãƒˆãƒ”ãƒƒã‚¯åˆ¥
        by_department: éƒ¨é–€åˆ¥
        by_kb_type: KBã‚¿ã‚¤ãƒ—åˆ¥
        gaps: ã‚®ãƒ£ãƒƒãƒ—ãƒªã‚¹ãƒˆ
        generated_at: ç”Ÿæˆæ—¥æ™‚
    """

    overall: CoverageStats
    by_topic: list[TopicCoverage] = field(default_factory=list)
    by_department: dict[str, CoverageStats] = field(default_factory=dict)
    by_kb_type: dict[str, CoverageStats] = field(default_factory=dict)
    gaps: list[GapAnalysis] = field(default_factory=list)
    trends: dict[str, str] = field(default_factory=dict)
    generated_at: datetime = field(default_factory=datetime.now)
    period_start: datetime | None = None
    period_end: datetime | None = None


@dataclass
class CoverageDashboardConfig:
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š."""

    # é–¾å€¤
    excellent_threshold: float = 0.9
    good_threshold: float = 0.7
    fair_threshold: float = 0.5

    # ã‚®ãƒ£ãƒƒãƒ—åˆ†æ
    min_queries_for_gap: int = 5
    critical_hit_rate_threshold: float = 0.3

    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    trend_comparison_days: int = 7


class CoverageDashboard:
    """ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰.

    çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’å¯è¦–åŒ–ã€‚

    Example:
        >>> dashboard = CoverageDashboard()
        >>>
        >>> # ã‚¯ã‚¨ãƒªãƒ­ã‚°ã‚’è¨˜éŒ²
        >>> await dashboard.log_query(
        ...     query_id="q-001",
        ...     query_text="å¹´ä¼‘ã®ä»˜ä¸æ—¥æ•°",
        ...     topic="äººäº‹",
        ...     hit=True,
        ...     hit_count=3,
        ... )
        >>>
        >>> # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        >>> report = await dashboard.get_coverage_report()
    """

    def __init__(
        self,
        config: CoverageDashboardConfig | None = None,
    ) -> None:
        """åˆæœŸåŒ–.

        Args:
            config: è¨­å®š
        """
        self._config = config or CoverageDashboardConfig()
        self._query_logs: dict[str, QueryLog] = {}
        self._logger = logging.getLogger(__name__)

    async def log_query(
        self,
        query_id: str,
        query_text: str,
        topic: str = "",
        department: str = "",
        kb_type: str = "",
        hit: bool = False,
        hit_count: int = 0,
        top_score: float = 0.0,
        response_time_ms: float = 0.0,
        user_id: str = "",
    ) -> QueryLog:
        """ã‚¯ã‚¨ãƒªãƒ­ã‚°ã‚’è¨˜éŒ².

        Args:
            query_id: ã‚¯ã‚¨ãƒªID
            query_text: ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆ
            topic: ãƒˆãƒ”ãƒƒã‚¯
            department: éƒ¨é–€
            kb_type: KBã‚¿ã‚¤ãƒ—
            hit: å‘½ä¸­ã—ãŸã‹
            hit_count: å‘½ä¸­æ•°
            top_score: ãƒˆãƒƒãƒ—ã‚¹ã‚³ã‚¢
            response_time_ms: å¿œç­”æ™‚é–“
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID

        Returns:
            ã‚¯ã‚¨ãƒªãƒ­ã‚°
        """
        log = QueryLog(
            query_id=query_id,
            query_text=query_text,
            topic=topic,
            department=department,
            kb_type=kb_type,
            hit=hit,
            hit_count=hit_count,
            top_score=top_score,
            response_time_ms=response_time_ms,
            user_id=user_id,
        )

        self._query_logs[query_id] = log

        return log

    async def get_coverage_report(
        self,
        since: datetime | None = None,
        until: datetime | None = None,
    ) -> CoverageReport:
        """ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ.

        Args:
            since: é–‹å§‹æ—¥æ™‚
            until: çµ‚äº†æ—¥æ™‚

        Returns:
            ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆ
        """
        logs = self._get_logs(since, until)

        report = CoverageReport(
            overall=self._calculate_stats(logs),
            period_start=since,
            period_end=until,
        )

        # ãƒˆãƒ”ãƒƒã‚¯åˆ¥
        by_topic = self._group_by_topic(logs)
        for topic, topic_logs in by_topic.items():
            stats = self._calculate_stats(topic_logs)
            sample_misses = [log.query_text for log in topic_logs if not log.hit][:5]

            topic_coverage = TopicCoverage(
                topic=topic,
                stats=stats,
                sample_misses=sample_misses,
                recommendations=self._generate_recommendations(stats),
                trend=self._calculate_trend(topic, logs),
            )
            report.by_topic.append(topic_coverage)

        # ãƒˆãƒ”ãƒƒã‚¯åˆ¥ã‚’å‘½ä¸­ç‡ã§ã‚½ãƒ¼ãƒˆ
        report.by_topic.sort(key=lambda x: x.stats.hit_rate)

        # éƒ¨é–€åˆ¥
        by_dept = self._group_by_department(logs)
        for dept, dept_logs in by_dept.items():
            report.by_department[dept] = self._calculate_stats(dept_logs)

        # KBã‚¿ã‚¤ãƒ—åˆ¥
        by_kb = self._group_by_kb_type(logs)
        for kb_type, kb_logs in by_kb.items():
            report.by_kb_type[kb_type] = self._calculate_stats(kb_logs)

        # ã‚®ãƒ£ãƒƒãƒ—åˆ†æ
        report.gaps = self._analyze_gaps(logs)

        return report

    def _get_logs(
        self,
        since: datetime | None = None,
        until: datetime | None = None,
    ) -> list[QueryLog]:
        """ãƒ­ã‚°ã‚’å–å¾—."""
        logs = list(self._query_logs.values())

        if since:
            logs = [l for l in logs if l.created_at >= since]
        if until:
            logs = [l for l in logs if l.created_at <= until]

        return logs

    def _calculate_stats(self, logs: list[QueryLog]) -> CoverageStats:
        """çµ±è¨ˆã‚’è¨ˆç®—."""
        if not logs:
            return CoverageStats()

        total = len(logs)
        hit_logs = [l for l in logs if l.hit]
        miss_logs = [l for l in logs if not l.hit]

        stats = CoverageStats(
            total_queries=total,
            hit_queries=len(hit_logs),
            miss_queries=len(miss_logs),
            hit_rate=len(hit_logs) / total,
            avg_hit_count=(sum(l.hit_count for l in hit_logs) / len(hit_logs) if hit_logs else 0),
            avg_top_score=(sum(l.top_score for l in hit_logs) / len(hit_logs) if hit_logs else 0),
            avg_response_time_ms=(sum(l.response_time_ms for l in logs) / total),
        )

        # ãƒ¬ãƒ™ãƒ«åˆ¤å®š
        if stats.hit_rate >= self._config.excellent_threshold:
            stats.level = CoverageLevel.EXCELLENT
        elif stats.hit_rate >= self._config.good_threshold:
            stats.level = CoverageLevel.GOOD
        elif stats.hit_rate >= self._config.fair_threshold:
            stats.level = CoverageLevel.FAIR
        else:
            stats.level = CoverageLevel.POOR

        return stats

    def _group_by_topic(self, logs: list[QueryLog]) -> dict[str, list[QueryLog]]:
        """ãƒˆãƒ”ãƒƒã‚¯åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–."""
        by_topic: dict[str, list[QueryLog]] = defaultdict(list)
        for log in logs:
            topic = log.topic or "æœªåˆ†é¡"
            by_topic[topic].append(log)
        return dict(by_topic)

    def _group_by_department(self, logs: list[QueryLog]) -> dict[str, list[QueryLog]]:
        """éƒ¨é–€åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–."""
        by_dept: dict[str, list[QueryLog]] = defaultdict(list)
        for log in logs:
            dept = log.department or "æœªåˆ†é¡"
            by_dept[dept].append(log)
        return dict(by_dept)

    def _group_by_kb_type(self, logs: list[QueryLog]) -> dict[str, list[QueryLog]]:
        """KBã‚¿ã‚¤ãƒ—åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–."""
        by_kb: dict[str, list[QueryLog]] = defaultdict(list)
        for log in logs:
            kb = log.kb_type or "æœªåˆ†é¡"
            by_kb[kb].append(log)
        return dict(by_kb)

    def _generate_recommendations(self, stats: CoverageStats) -> list[str]:
        """æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ."""
        recommendations = []

        if stats.hit_rate < self._config.critical_hit_rate_threshold:
            recommendations.append("âš ï¸ å‘½ä¸­ç‡ãŒéå¸¸ã«ä½ã„ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¿½åŠ ãŒæ€¥å‹™ã§ã™ã€‚")
        elif stats.hit_rate < self._config.fair_threshold:
            recommendations.append("ğŸ“ å‘½ä¸­ç‡ãŒä½ã„ã§ã™ã€‚é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¿½åŠ ã‚’ã”æ¤œè¨ãã ã•ã„ã€‚")

        if stats.avg_top_score < 0.5:
            recommendations.append("ğŸ¯ æ¤œç´¢ç²¾åº¦ãŒä½ã„ã§ã™ã€‚è¡“èªè¾æ›¸ã®å……å®Ÿã‚’ã”æ¤œè¨ãã ã•ã„ã€‚")

        if stats.avg_response_time_ms > 2000:
            recommendations.append("â±ï¸ å¿œç­”æ™‚é–“ãŒé…ã„ã§ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æœ€é©åŒ–ã‚’ã”æ¤œè¨ãã ã•ã„ã€‚")

        return recommendations

    def _calculate_trend(self, topic: str, logs: list[QueryLog]) -> str:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—."""
        now = datetime.now()
        comparison_days = self._config.trend_comparison_days

        # ç›´è¿‘æœŸé–“
        recent_start = now - timedelta(days=comparison_days)
        recent_logs = [l for l in logs if l.topic == topic and l.created_at >= recent_start]

        # å‰æœŸé–“
        previous_start = recent_start - timedelta(days=comparison_days)
        previous_logs = [
            l for l in logs if l.topic == topic and previous_start <= l.created_at < recent_start
        ]

        if not recent_logs or not previous_logs:
            return "stable"

        recent_rate = len([l for l in recent_logs if l.hit]) / len(recent_logs)
        previous_rate = len([l for l in previous_logs if l.hit]) / len(previous_logs)

        diff = recent_rate - previous_rate
        if diff > 0.05:
            return "improving"
        if diff < -0.05:
            return "declining"
        return "stable"

    def _analyze_gaps(self, logs: list[QueryLog]) -> list[GapAnalysis]:
        """ã‚®ãƒ£ãƒƒãƒ—åˆ†æ."""
        gaps = []
        by_topic = self._group_by_topic(logs)

        for topic, topic_logs in by_topic.items():
            if len(topic_logs) < self._config.min_queries_for_gap:
                continue

            hit_rate = len([l for l in topic_logs if l.hit]) / len(topic_logs)

            if hit_rate >= self._config.good_threshold:
                continue

            # æ·±åˆ»åº¦åˆ¤å®š
            if hit_rate < self._config.critical_hit_rate_threshold:
                severity = "critical"
            elif hit_rate < self._config.fair_threshold:
                severity = "high"
            else:
                severity = "medium"

            # ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒª
            miss_logs = [l for l in topic_logs if not l.hit]
            sample_queries = [l.query_text for l in miss_logs[:5]]

            gap = GapAnalysis(
                topic=topic,
                query_count=len(topic_logs),
                hit_rate=hit_rate,
                severity=severity,
                sample_queries=sample_queries,
                suggested_content=[
                    f"ã€Œ{topic}ã€ã«é–¢ã™ã‚‹FAQãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
                    f"ã€Œ{topic}ã€ã®ç”¨èªè¾æ›¸ã‚¨ãƒ³ãƒˆãƒªãƒ¼",
                ],
            )
            gaps.append(gap)

        # æ·±åˆ»åº¦ã§ã‚½ãƒ¼ãƒˆ
        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
        gaps.sort(key=lambda g: severity_order.get(g.severity, 99))

        return gaps

    def get_summary(self) -> dict[str, Any]:
        """ã‚µãƒãƒªãƒ¼ã‚’å–å¾—."""
        logs = self._get_logs()

        if not logs:
            return {"status": "no_data"}

        stats = self._calculate_stats(logs)

        return {
            "status": "ok",
            "overall_hit_rate": stats.hit_rate,
            "level": stats.level.value,
            "total_queries": stats.total_queries,
            "topics_count": len(self._group_by_topic(logs)),
            "gaps_count": len(self._analyze_gaps(logs)),
        }


__all__ = [
    "CoverageDashboard",
    "CoverageDashboardConfig",
    "CoverageLevel",
    "CoverageReport",
    "CoverageStats",
    "GapAnalysis",
    "QueryLog",
    "TopicCoverage",
]
