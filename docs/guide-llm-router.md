# LLM ãƒ¢ãƒ‡ãƒ«ãƒ«ãƒ¼ã‚¿ãƒ¼ ã‚¬ã‚¤ãƒ‰

> **ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0
> **æ›´æ–°æ—¥**: 2025-01-20

---

## ğŸ“‹ æ¦‚è¦

AgentFlow ã® **ModelRouter** ã¯ã€è¤‡æ•°ã® LLM ãƒ¢ãƒ‡ãƒ«ã‚’çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ç®¡ç†ã—ã€è‡ªå‹•åˆ‡æ›¿ãƒ»ã‚³ã‚¹ãƒˆæœ€é©åŒ–ãƒ»è² è·åˆ†æ•£ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### ä¸»ãªç‰¹å¾´

| ç‰¹å¾´ | èª¬æ˜ |
|------|------|
| ğŸ”„ **è‡ªå‹•åˆ‡æ›¿** | éšœå®³æ™‚ã«è‡ªå‹•ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ |
| ğŸ’° **ã‚³ã‚¹ãƒˆæœ€é©åŒ–** | äºˆç®—å†…ã§æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ |
| âš¡ **ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | å¿œç­”æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° |
| ğŸ“Š **çµ±è¨ˆè¿½è·¡** | ä½¿ç”¨é‡ãƒ»ã‚³ã‚¹ãƒˆãƒ»ã‚¨ãƒ©ãƒ¼ç‡ã‚’ç›£è¦– |
| ğŸ¯ **èƒ½åŠ›ãƒãƒƒãƒãƒ³ã‚°** | ã‚¿ã‚¹ã‚¯ã«æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•é¸æŠ |

---

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### åŸºæœ¬çš„ãªä½¿ç”¨

```python
from agentflow.llm import (
    ModelRouter,
    LLMConfig,
    LLMMessage,
    RoutingStrategy,
    RoutingConfig,
)

# ãƒ¢ãƒ‡ãƒ«è¨­å®š
models = {
    "primary": LLMConfig(
        provider="anthropic",
        model="claude-3-5-sonnet-20241022",
        api_key="sk-ant-...",
    ),
    "fallback": LLMConfig(
        provider="openai",
        model="gpt-4o",
        api_key="sk-...",
    ),
    "economy": LLMConfig(
        provider="openai",
        model="gpt-4o-mini",
        api_key="sk-...",
    ),
}

# ãƒ«ãƒ¼ã‚¿ãƒ¼ä½œæˆ
router = ModelRouter(
    models=models,
    routing_config=RoutingConfig(
        strategy=RoutingStrategy.BALANCED,
        fallback_models=["fallback", "economy"],
        max_retries=3,
    ),
)

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ï¼ˆè‡ªå‹•ã§ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«é¸æŠï¼‰
messages = [LLMMessage(role="user", content="Hello!")]
response = await router.chat(messages)
print(response.content)
```

### ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•è¨­å®š

```python
from agentflow.llm import create_router_from_env

# OPENAI_API_KEY, ANTHROPIC_API_KEY ã‚’è‡ªå‹•æ¤œå‡º
router = create_router_from_env()
response = await router.chat(messages)
```

---

## ğŸ“‹ å¯¾å¿œãƒ¢ãƒ‡ãƒ«

### OpenAI

| ãƒ¢ãƒ‡ãƒ« | ãƒ†ã‚£ã‚¢ | ç‰¹å¾´ | å…¥åŠ›ã‚³ã‚¹ãƒˆ |
|--------|--------|------|-----------|
| gpt-4o | Premium | ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã€æœ€æ–° | $5/M tokens |
| gpt-4o-mini | Economy | é«˜ã‚³ã‚¹ãƒ‘ | $0.15/M tokens |
| gpt-4-turbo | Premium | é•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ | $10/M tokens |

### Anthropic

| ãƒ¢ãƒ‡ãƒ« | ãƒ†ã‚£ã‚¢ | ç‰¹å¾´ | å…¥åŠ›ã‚³ã‚¹ãƒˆ |
|--------|--------|------|-----------|
| claude-3-5-sonnet | Premium | ã‚³ãƒ¼ãƒ‰æœ€å¼· | $3/M tokens |
| claude-3-5-haiku | Economy | é«˜é€Ÿ | $1/M tokens |
| claude-3-opus | Premium | æ¨è«–æœ€å¼· | $15/M tokens |

### Google

| ãƒ¢ãƒ‡ãƒ« | ãƒ†ã‚£ã‚¢ | ç‰¹å¾´ | å…¥åŠ›ã‚³ã‚¹ãƒˆ |
|--------|--------|------|-----------|
| gemini-1.5-pro | Premium | 100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ | $1.25/M tokens |
| gemini-1.5-flash | Economy | è¶…é«˜é€Ÿ | $0.075/M tokens |

### DeepSeek

| ãƒ¢ãƒ‡ãƒ« | ãƒ†ã‚£ã‚¢ | ç‰¹å¾´ | å…¥åŠ›ã‚³ã‚¹ãƒˆ |
|--------|--------|------|-----------|
| deepseek-chat | Economy | ã‚³ã‚¹ãƒ‘æœ€å¼· | $0.14/M tokens |
| deepseek-reasoner | Standard | æ¨ç†ç‰¹åŒ– | $0.55/M tokens |

---

## ğŸ¯ ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥

### æˆ¦ç•¥ä¸€è¦§

| æˆ¦ç•¥ | èª¬æ˜ | ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ |
|------|------|------------|
| `COST_OPTIMIZED` | æœ€å®‰ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ | äºˆç®—é‡è¦– |
| `QUALITY_OPTIMIZED` | æœ€é«˜å“è³ªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ | å“è³ªé‡è¦– |
| `BALANCED` | ã‚³ã‚¹ãƒˆãƒ»å“è³ªãƒ»ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®ãƒãƒ©ãƒ³ã‚¹ | ä¸€èˆ¬ç”¨é€” |
| `LATENCY_OPTIMIZED` | æœ€é€Ÿãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç† |
| `ROUND_ROBIN` | é †ç•ªã«ä½¿ç”¨ | è² è·åˆ†æ•£ |
| `CAPABILITY_MATCH` | å¿…è¦ãªèƒ½åŠ›ã«åŸºã¥ã„ã¦é¸æŠ | ç‰¹æ®Šã‚¿ã‚¹ã‚¯ |

### æˆ¦ç•¥è¨­å®š

```python
from agentflow.llm import RoutingStrategy, RoutingConfig

# ã‚³ã‚¹ãƒˆæœ€é©åŒ–
config = RoutingConfig(
    strategy=RoutingStrategy.COST_OPTIMIZED,
    cost_limit_per_request=0.01,  # $0.01/ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸Šé™
)

# å“è³ªæœ€é©åŒ–
config = RoutingConfig(
    strategy=RoutingStrategy.QUALITY_OPTIMIZED,
    preferred_providers=["anthropic"],  # Anthropic ã‚’å„ªå…ˆ
)

# ãƒãƒ©ãƒ³ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
config = RoutingConfig(
    strategy=RoutingStrategy.BALANCED,
    fallback_models=["fallback", "economy"],
    max_retries=3,
)
```

---

## ğŸ¯ èƒ½åŠ›ãƒ™ãƒ¼ã‚¹ã®é¸æŠ

### ãƒ¢ãƒ‡ãƒ«èƒ½åŠ›

```python
from agentflow.llm import ModelCapability

# èƒ½åŠ›ã‚¿ã‚¤ãƒ—
capabilities = [
    ModelCapability.CHAT,           # å¯¾è©±
    ModelCapability.CODE,           # ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
    ModelCapability.REASONING,      # æ¨è«–
    ModelCapability.VISION,         # ç”»åƒç†è§£
    ModelCapability.FUNCTION_CALLING,  # é–¢æ•°å‘¼ã³å‡ºã—
]
```

### èƒ½åŠ›ã«åŸºã¥ãé¸æŠ

```python
# ã‚³ãƒ¼ãƒ‰ã¨æ¨è«–ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯
response = await router.chat_with_capability(
    messages,
    required_capabilities=[
        ModelCapability.CODE,
        ModelCapability.REASONING,
    ],
)
```

---

## ğŸ’° ã‚³ã‚¹ãƒˆç®¡ç†

### ã‚³ã‚¹ãƒˆåˆ¶é™

```python
# ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚ãŸã‚Šã®ã‚³ã‚¹ãƒˆä¸Šé™
response = await router.chat_cost_limited(
    messages,
    max_cost_per_request=0.01,  # $0.01
)
```

### ã‚³ã‚¹ãƒˆè¿½è·¡

```python
# ç·ã‚³ã‚¹ãƒˆå–å¾—
total_cost = router.get_total_cost()
print(f"ç·ã‚³ã‚¹ãƒˆ: ${total_cost:.4f}")

# ãƒ¢ãƒ‡ãƒ«åˆ¥ã‚³ã‚¹ãƒˆ
breakdown = router.get_cost_breakdown()
for model, cost in breakdown.items():
    print(f"{model}: ${cost:.4f}")
```

---

## ğŸ“Š çµ±è¨ˆã¨ç›£è¦–

### çµ±è¨ˆå–å¾—

```python
# å…¨ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆ
stats = router.get_stats()

for model, s in stats.items():
    print(f"=== {model} ===")
    print(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {s.total_requests}")
    print(f"æˆåŠŸç‡: {(1 - s.error_rate) * 100:.1f}%")
    print(f"å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {s.avg_latency_ms:.0f}ms")
    print(f"ã‚³ã‚¹ãƒˆ: ${s.total_cost:.4f}")
```

### çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ

```python
# å…¨çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ
router.reset_stats()

# ç‰¹å®šãƒ¢ãƒ‡ãƒ«ã®ã¿
router.reset_stats("economy")
```

---

## ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ãƒªãƒˆãƒ©ã‚¤

### è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

```python
config = RoutingConfig(
    strategy=RoutingStrategy.QUALITY_OPTIMIZED,
    fallback_models=["fallback", "economy"],  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é †åº
    max_retries=3,
    retry_delay=1.0,  # ãƒªãƒˆãƒ©ã‚¤é–“éš”ï¼ˆç§’ï¼‰
)

# primary ãŒå¤±æ•— â†’ fallback â†’ economy ã¨è©¦è¡Œ
router = ModelRouter(models=models, routing_config=config)
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
try:
    response = await router.chat(messages)
except Exception as e:
    # å…¨ãƒ¢ãƒ‡ãƒ«ãŒå¤±æ•—ã—ãŸå ´åˆ
    logger.error(f"å…¨ãƒ¢ãƒ‡ãƒ«å¤±æ•—: {e}")
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
```

---

## ğŸ”§ å‹•çš„ãƒ¢ãƒ‡ãƒ«ç®¡ç†

### ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ ãƒ»å‰Šé™¤

```python
# ãƒ¢ãƒ‡ãƒ«è¿½åŠ 
router.add_model(
    "new_model",
    LLMConfig(provider="openai", model="gpt-4", api_key="..."),
)

# ãƒ¢ãƒ‡ãƒ«å‰Šé™¤
router.remove_model("old_model")

# ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
models = router.list_models()
```

### ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—

```python
from agentflow.llm import MODELS

# ç™»éŒ²æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±
info = MODELS.get("claude-3-5-sonnet-20241022")
if info:
    print(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {info.provider}")
    print(f"ãƒ†ã‚£ã‚¢: {info.tier}")
    print(f"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {info.context_window}")
    print(f"ã‚³ã‚¹ãƒˆ: ${info.input_cost_per_1k}/1K tokens")
```

---

## ğŸ—ï¸ Agent çµ±åˆ

### SkillEngine ã¨ã®çµ±åˆ

```python
from agentflow.skills import SkillEngine
from agentflow.llm import ModelRouter, create_router_from_env

router = create_router_from_env()
engine = SkillEngine()

@engine.tool("smart_chat")
async def smart_chat(message: str, task_type: str = "general") -> str:
    """ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""
    
    messages = [LLMMessage(role="user", content=message)]
    
    if task_type == "code":
        # ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¹ã‚¯ã¯é«˜å“è³ªãƒ¢ãƒ‡ãƒ«
        response = await router.chat_with_capability(
            messages,
            required_capabilities=[ModelCapability.CODE],
        )
    elif task_type == "simple":
        # ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã¯ã‚³ã‚¹ãƒˆé‡è¦–
        response = await router.chat_cost_limited(messages, max_cost=0.001)
    else:
        # ä¸€èˆ¬ã‚¿ã‚¹ã‚¯ã¯ãƒãƒ©ãƒ³ã‚¹
        response = await router.chat(messages)
    
    return response.content
```

---

## ğŸ“š é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [å†…è”µ Skills ã‚¬ã‚¤ãƒ‰](guide-builtin-skills.md) - DB/æ±ºæ¸ˆ/èªè¨¼
- [Skills ã‚¬ã‚¤ãƒ‰](guide-skills.md) - è‡ªå‹•é€²åŒ–ã‚·ã‚¹ãƒ†ãƒ 
- [API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](api.md) - è©³ç´° API

