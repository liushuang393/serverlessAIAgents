# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¦‚è¦

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€AIãƒ»æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ç”¨ã™ã‚‹å„ç¨®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

### ğŸ¤– AIãƒ»LLMé–¢é€£
- **`LLMProvider.py`** - è¤‡æ•°LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆOpenAIã€Anthropicã€Googleã€Ollamaç­‰ï¼‰ã¸ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- **`embedding_utils.py`** - åŸ‹ã‚è¾¼ã¿APIï¼ˆOpenAIã€Azureã€Googleã€Cohereã€HuggingFaceã€Jinaç­‰ï¼‰ã®çµ±åˆç®¡ç†
- **`vector_utils.py`** - ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆFAISSã€Pineconeã€Qdrantã€Chromaç­‰ï¼‰ã®çµ±ä¸€æ“ä½œ

### ğŸ” æ¤œç´¢ãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£
- **`websearch_utils.py`** - Webæ¤œç´¢APIï¼ˆGoogleã€Bingã€DuckDuckGoã€Braveã€SerpApiï¼‰ã®çµ±åˆ
- **`text_utils.py`** - ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå›ºå®šã‚µã‚¤ã‚ºã€æ–‡ãƒ™ãƒ¼ã‚¹ã€æ®µè½ãƒ™ãƒ¼ã‚¹ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ï¼‰
- **`audio_utils.py`** - Text-to-Speechï¼ˆAmazon Pollyã€Google TTSã€Azure TTSã€ElevenLabsç­‰ï¼‰

### ğŸ› ï¸ ã‚·ã‚¹ãƒ†ãƒ ãƒ»ãƒ‡ãƒãƒƒã‚°é–¢é€£
- **`viz_utils.py`** - Mermaidå›³ç”Ÿæˆã€ã‚³ãƒ¼ãƒ«ã‚¹ã‚¿ãƒƒã‚¯ãƒ‡ãƒãƒƒã‚°ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

## ğŸš€ ä¸»ãªæ©Ÿèƒ½

### 1. LLMçµ±åˆç®¡ç† (`LLMProvider.py`)
è¤‡æ•°ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆOpenAIã€Anthropicã€Googleã€HuggingFaceï¼‰ã‚’çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ç®¡ç†ã€‚

**ä¸»è¦æ©Ÿèƒ½:**
- çµ±ä¸€ã•ã‚ŒãŸAPIå‘¼ã³å‡ºã—ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- ãƒ¡ãƒ¢ãƒªå†…ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ï¼ˆ@lru_cacheä½¿ç”¨ï¼‰
- ãƒãƒ£ãƒƒãƒˆå±¥æ­´å‡¦ç†æ©Ÿèƒ½
- è©³ç´°ãƒ­ã‚°æ©Ÿèƒ½
- å†è©¦è¡Œå¯¾å¿œ
- è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½

```python
# OpenAI APIä½¿ç”¨ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹ï¼‰
response = generate("ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œã«ã¤ã„ã¦æ•™ãˆã¦", use_cache=True)

# Anthropic APIä½¿ç”¨
response = generate_anthropic("é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã«ã¤ã„ã¦èª¬æ˜ã—ã¦")

# Google APIä½¿ç”¨
response = generate_google("AIã®æœªæ¥ã«ã¤ã„ã¦æ•™ãˆã¦")

# HuggingFace APIä½¿ç”¨
response = generate_huggingface("æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´å‡¦ç†
messages = [
    {"role": "user", "content": "ã“ã‚“ã«ã¡ã¯"},
    {"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"},
    {"role": "user", "content": "å¤©æ°—ã«ã¤ã„ã¦æ•™ãˆã¦"}
]
response = call_llm_with_messages(messages, use_cache=True)

# å†è©¦è¡Œæ©Ÿèƒ½ä»˜ãå‘¼ã³å‡ºã—
response = generate("è³ªå•å†…å®¹", cur_retry=1, use_cache=False)
```

### 2. åŸ‹ã‚è¾¼ã¿ç®¡ç† (`embedding_utils.py`)
```python
from embedding_utils import embed, setup_embedding_providers

# ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿
embedding = embed("ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆã§ã™")
embeddings = embed(["ãƒ†ã‚­ã‚¹ãƒˆ1", "ãƒ†ã‚­ã‚¹ãƒˆ2", "ãƒ†ã‚­ã‚¹ãƒˆ3"])

# ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
config = {
    "openai": {"type": "openai", "api_key": "your-key", "default": True},
    "cohere": {"type": "cohere", "api_key": "your-key"}
}
setup_embedding_providers(config)
```

### 3. ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (`vector_utils.py`)
```python
from vector_utils import create_collection, upsert_documents, search_vectors, VectorDocument

# ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
create_collection("my_collection", dimension=1536, provider="faiss")

# æ–‡æ›¸è¿½åŠ 
documents = [
    VectorDocument("doc1", [0.1, 0.2, 0.3], {"title": "æ–‡æ›¸1"}, "ã“ã‚Œã¯æ–‡æ›¸1ã§ã™"),
    VectorDocument("doc2", [0.4, 0.5, 0.6], {"title": "æ–‡æ›¸2"}, "ã“ã‚Œã¯æ–‡æ›¸2ã§ã™")
]
upsert_documents("my_collection", documents)

# æ¤œç´¢
query_vector = [0.1, 0.2, 0.3]
results = search_vectors("my_collection", query_vector, top_k=5)
```

### 4. Webæ¤œç´¢ (`websearch_utils.py`)
```python
from websearch_utils import search_web, setup_search_providers

# æ¤œç´¢å®Ÿè¡Œ
results = search_web("Python ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", num_results=5, provider="duckduckgo")

for result in results:
    print(f"ã‚¿ã‚¤ãƒˆãƒ«: {result.title}")
    print(f"URL: {result.url}")
    print(f"æ¦‚è¦: {result.snippet}")
```

### 5. ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚° (`text_utils.py`)
```python
from text_utils import chunk_text, preprocess_text

# ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
clean_text = preprocess_text("<p>ã“ã‚Œã¯   ãƒ†ã‚¹ãƒˆã§ã™</p>")

# å›ºå®šã‚µã‚¤ã‚ºãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°
chunks = chunk_text(text, chunker_type="fixed", chunk_size=1000, overlap=200)

# æ–‡ãƒ™ãƒ¼ã‚¹ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°
chunks = chunk_text(text, chunker_type="sentence", max_sentences=5)

# ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ï¼ˆåŸ‹ã‚è¾¼ã¿é–¢æ•°ãŒå¿…è¦ï¼‰
def embedding_func(text):
    return embed(text)  # embedding_utilsä½¿ç”¨

chunks = chunk_text(
    text, 
    chunker_type="semantic", 
    embedding_function=embedding_func,
    similarity_threshold=0.7
)
```

### 6. Text-to-Speech (`audio_utils.py`)
```python
from audio_utils import text_to_speech, setup_tts_providers, synthesize_long_text

# éŸ³å£°ç”Ÿæˆ
text_to_speech("ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œ", "output.mp3", provider="amazon_polly")

# é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†å‰²éŸ³å£°ç”Ÿæˆ
long_text = "ã“ã‚Œã¯éå¸¸ã«é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã§ã™..." * 100
audio_files = synthesize_long_text(long_text, "output_dir/", max_length=5000)
```

### 7. å¯è¦–åŒ–ãƒ»ãƒ‡ãƒãƒƒã‚° (`viz_utils.py`)
```python
from viz_utils import build_mermaid, profile_execution, debug_call_stack

# Mermaidå›³ç”Ÿæˆ
mermaid_code = build_mermaid(flow_object, direction="LR")

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
@profile_execution("my_function")
def my_function():
    # å‡¦ç†å†…å®¹
    pass

# ã‚³ãƒ¼ãƒ«ã‚¹ã‚¿ãƒƒã‚¯ãƒ‡ãƒãƒƒã‚°
debug_call_stack("BaseNode")
```

## ğŸ”§ è¨­å®šã¨ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ç’°å¢ƒå¤‰æ•°
å„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã§ãã¾ã™ï¼š

```bash
# LLM
export OPENAI_API_KEY="your-openai-key"
export ANTHROPIC_API_KEY="your-anthropic-key"
export GOOGLE_API_KEY="your-google-key"

# åŸ‹ã‚è¾¼ã¿
export COHERE_API_KEY="your-cohere-key"
export HUGGINGFACE_API_KEY="your-hf-key"
export JINA_API_KEY="your-jina-key"

# Webæ¤œç´¢
export GOOGLE_SEARCH_API_KEY="your-google-search-key"
export GOOGLE_SEARCH_CX_ID="your-cx-id"
export BING_SEARCH_API_KEY="your-bing-key"

# TTS
export AWS_ACCESS_KEY_ID="your-aws-key"
export AWS_SECRET_ACCESS_KEY="your-aws-secret"
export ELEVENLABS_API_KEY="your-elevenlabs-key"
```

### ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šä¾‹
```python
# çµ±åˆè¨­å®šä¾‹
from llm_utils import setup_providers as setup_llm
from embedding_utils import setup_embedding_providers
from websearch_utils import setup_search_providers
from audio_utils import setup_tts_providers

# LLMè¨­å®š
llm_config = {
    "openai": {
        "type": "openai",
        "api_key": os.getenv("OPENAI_API_KEY"),
        "model": "gpt-4",
        "default": True
    },
    "anthropic": {
        "type": "anthropic", 
        "api_key": os.getenv("ANTHROPIC_API_KEY"),
        "model": "claude-3-sonnet-20240229"
    }
}
setup_llm(llm_config)

# åŸ‹ã‚è¾¼ã¿è¨­å®š
embedding_config = {
    "openai": {
        "type": "openai",
        "api_key": os.getenv("OPENAI_API_KEY"),
        "default": True
    }
}
setup_embedding_providers(embedding_config)
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆ

ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ `__temp_tests__/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã•ã‚Œã¦ã„ã¾ã™ï¼š

```bash
# ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
cd __temp_tests__
python run_tests.py

# ç‰¹å®šã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
python run_tests.py llm_utils
python run_tests.py embedding_utils
python run_tests.py text_utils
```

## ğŸ“‹ ä¾å­˜é–¢ä¿‚

### å¿…é ˆ
- `numpy` - æ•°å€¤è¨ˆç®—
- `requests` - HTTPé€šä¿¡

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæ©Ÿèƒ½åˆ¥ï¼‰
- **LLM**: `openai`, `anthropic`, `google-generativeai`
- **åŸ‹ã‚è¾¼ã¿**: `cohere`, `boto3`, `google-cloud-aiplatform`
- **ãƒ™ã‚¯ãƒˆãƒ«DB**: `faiss-cpu`, `pinecone-client`, `chromadb`
- **ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†**: `nltk`
- **éŸ³å£°**: `boto3`, `google-cloud-texttospeech`, `azure-cognitiveservices-speech`
- **ãã®ä»–**: `aiohttp`, `pydub`, `librosa`

## ğŸ”„ äº’æ›æ€§

æ—¢å­˜ã® `LLMProvider.py` ã¨ã®äº’æ›æ€§ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ï¼š
- `generate()` é–¢æ•°
- `call_llm_with_messages()` é–¢æ•°  
- `generate_anthropic()` é–¢æ•°
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½

## ğŸ“ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«å¾“ã„ã¾ã™ã€‚

## ğŸ¤ è²¢çŒ®

ãƒã‚°å ±å‘Šã‚„æ©Ÿèƒ½è¦æœ›ã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Issueãƒˆãƒ©ãƒƒã‚«ãƒ¼ã¾ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
