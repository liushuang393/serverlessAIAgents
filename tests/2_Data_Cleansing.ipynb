{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a7a63e",
   "metadata": {},
   "source": [
    "② データクレンジング（Data Cleansing）\n",
    "▶ 異常値除去（Outlier Removal）\n",
    "データの異常値を検出し除去する処理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98cb8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.413204\n",
      "1   -0.408246\n",
      "2   -0.410725\n",
      "3    2.041229\n",
      "4   -0.405767\n",
      "5   -0.403287\n",
      "Name: z_score, dtype: float64\n",
      "===========================\n",
      "   value   z_score\n",
      "3   1000  2.041229\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'value': [10, 12, 11, 1000, 13, 14]})\n",
    "\n",
    "# Zスコアによる異常値除去\n",
    "df['z_score'] = (df['value'] - df['value'].mean()) / df['value'].std()\n",
    "clean_df = df[np.abs(df['z_score']) > 1]\n",
    "print(df['z_score'])\n",
    "print(\"===========================\")\n",
    "print(clean_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf0d1c",
   "metadata": {},
   "source": [
    "▶ 欠損値処理（Missing Value Handling）\n",
    "欠損値を検出・処理する方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d138ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  NaN  5.0\n",
      "2  3.0  NaN\n",
      "==========平均値で補完=================\n",
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  2.0  5.0\n",
      "2  3.0  4.5\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': [1, np.nan, 3], 'B': [4, 5, np.nan]})\n",
    "print(df)\n",
    "\n",
    "# 平均値で補完\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "print(\"==========平均値で補完=================\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17f432",
   "metadata": {},
   "source": [
    "▶ 正規化・標準化（Normalization/Standardization）\n",
    "データを一定範囲にスケーリングする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dfd681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1 200]\n",
      " [  2 300]\n",
      " [  3 400]]\n",
      "==========正規化（0～1の範囲）=================\n",
      "[[0.  0. ]\n",
      " [0.5 0.5]\n",
      " [1.  1. ]]\n",
      "==========標準化（平均0、分散1）=================\n",
      "[[-1.22474487 -1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "data = np.array([[1, 200], [2, 300], [3, 400]])\n",
    "\n",
    "print(data)\n",
    "\n",
    "# 正規化（0～1の範囲）\n",
    "scaler = MinMaxScaler()\n",
    "normalized = scaler.fit_transform(data)\n",
    "print(\"==========正規化（0～1の範囲）=================\")\n",
    "print(normalized)\n",
    "\n",
    "# 標準化（平均0、分散1）\n",
    "scaler_std = StandardScaler()\n",
    "standardized = scaler_std.fit_transform(data)\n",
    "print(\"==========標準化（平均0、分散1）=================\")\n",
    "print(standardized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b73a81",
   "metadata": {},
   "source": [
    "▶ テキストクレンジング（NLP用）\n",
    "不要な記号・記述を除去し、形態素解析を行う。\n",
    "\n",
    "| オプション       | 説明                                                   | 出力例                          |\n",
    "| --------------- | -------------------------------------------------------| -------------------------------|\n",
    "| **`-Owakati`**  | 単語をスペースで区切った「分かち書き」形式                 | `今日は 良い 天気 です`         |\n",
    "| **`-Oyomi`**    | 入力文を「読み仮名（カタカナ）」で表示                     | `キョウハヨイテンキデス`        |\n",
    "| **`-Ochasen`**  | 「茶筌」互換の詳細な解析結果を表示（品詞、活用などを含む）   | 品詞、読み、原形などが一覧で表示 |\n",
    "| **`-Odump`**    | MeCabの内部情報を出力（辞書、形態素解析処理の詳細）         | デバッグ用の詳細な情報          |\n",
    "| **`-Ojson`**    | JSON形式で解析結果を表示（辞書による）                     | JSONデータ形式                 |\n",
    "| **`-Ounidic`**  | UniDic辞書を用いた詳細解析（使用時にUniDicが必要）         | より細かな品詞分類・発音情報など  |\n",
    "| **`-Olattice`** | ラティス構造を表示（解析時の各候補やスコア表示）            | 解析の詳細候補                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d870535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIモデルを学習するために、データ前処理が重要です！ #AI\n",
      "==========MeCabによる形態素解析=================\n",
      "AI モデル を 学習 する ため に データ 前 処理 が 重要 です AI \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "\n",
    "text = 'AIモデルを学習するために、データ前処理が重要です！ #AI'\n",
    "print(text)\n",
    "\n",
    "# 正規表現で記号除去\n",
    "clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# MeCabによる形態素解析\n",
    "mecab = MeCab.Tagger('-Owakati')\n",
    "parsed = mecab.parse(clean_text)\n",
    "print(\"==========MeCabによる形態素解析=================\")\n",
    "print(parsed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
