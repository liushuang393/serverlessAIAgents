# -*- coding: utf-8 -*-
"""Decision Governance Engine - ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ.

å„Agentã®åŸºæœ¬æ©Ÿèƒ½ã¨Workflowã®å‹•ä½œã‚’æ¤œè¨¼ã™ã‚‹ã€‚
"""

import pytest

from apps.decision_governance_engine.agents.dao_agent import DaoAgent
from apps.decision_governance_engine.agents.fa_agent import FaAgent
from apps.decision_governance_engine.agents.gatekeeper_agent import GatekeeperAgent
from apps.decision_governance_engine.agents.qi_agent import QiAgent
from apps.decision_governance_engine.agents.review_agent import ReviewAgent
from apps.decision_governance_engine.agents.shu_agent import ShuAgent
from apps.decision_governance_engine.schemas.agent_schemas import (
    DaoOutput,
    FaOutput,
    ProblemType,
    QuestionCategory,
    ReviewVerdict,
    ShuOutput,
)
from apps.decision_governance_engine.schemas.input_schemas import (
    ConstraintSet,
    DecisionRequest,
)
from apps.decision_governance_engine.schemas.output_schemas import (
    DecisionReport,
    ExecutiveSummary,
)
from apps.decision_governance_engine.services.pdf_generator import PDFGeneratorService
from apps.decision_governance_engine.services.ui_components import (
    DecisionUIComponentBuilder,
)
from apps.decision_governance_engine.engine import DecisionEngine


class TestGatekeeperAgent:
    """GatekeeperAgentã®ãƒ†ã‚¹ãƒˆ."""

    @pytest.fixture
    def agent(self) -> GatekeeperAgent:
        """ãƒ†ã‚¹ãƒˆç”¨Agentã‚’ä½œæˆ."""
        return GatekeeperAgent()

    @pytest.mark.asyncio
    async def test_reject_weather_question(self, agent: GatekeeperAgent) -> None:
        """å¤©æ°—ã®è³ªå•ã¯æ‹’å¦ã•ã‚Œã‚‹."""
        result = await agent.run({"raw_question": "ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ"})
        assert result["is_acceptable"] is False
        assert result["category"] == QuestionCategory.FACTUAL_LOOKUP.value

    @pytest.mark.asyncio
    async def test_reject_system_inquiry(self, agent: GatekeeperAgent) -> None:
        """ã‚·ã‚¹ãƒ†ãƒ è³ªå•ã¯æ‹’å¦ã•ã‚Œã‚‹."""
        result = await agent.run({"raw_question": "ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã©ã†ã‚„ã£ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ"})
        assert result["is_acceptable"] is False
        assert result["category"] == QuestionCategory.SYSTEM_INQUIRY.value

    @pytest.mark.asyncio
    async def test_accept_trade_off_question(self, agent: GatekeeperAgent) -> None:
        """ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•è³ªå•ã¯å—ç†ã•ã‚Œã‚‹."""
        result = await agent.run({"raw_question": "æ–°è¦äº‹æ¥­Aã¨Bã®ã©ã¡ã‚‰ã«æŠ•è³‡ã™ã¹ãã‹åˆ¤æ–­ã—ãŸã„"})
        assert result["is_acceptable"] is True
        assert result["category"] == QuestionCategory.TRADE_OFF_CHOICE.value

    @pytest.mark.asyncio
    async def test_reject_short_question(self, agent: GatekeeperAgent) -> None:
        """çŸ­ã™ãã‚‹è³ªå•ã¯æ‹’å¦ã•ã‚Œã‚‹."""
        result = await agent.run({"raw_question": "ã©ã†ã™ã‚‹ï¼Ÿ"})
        assert result["is_acceptable"] is False


class TestDaoAgent:
    """DaoAgentã®ãƒ†ã‚¹ãƒˆ."""

    @pytest.fixture
    def agent(self) -> DaoAgent:
        """ãƒ†ã‚¹ãƒˆç”¨Agentã‚’ä½œæˆ."""
        return DaoAgent()

    @pytest.mark.asyncio
    async def test_analyze_trade_off(self, agent: DaoAgent) -> None:
        """ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•å•é¡Œã®åˆ†æ."""
        result = await agent.run({
            "question": "æ–°è¦äº‹æ¥­Aã¨Bã®ã©ã¡ã‚‰ã«æŠ•è³‡ã™ã¹ãã‹",
            "constraints": ["äºˆç®—1å„„å††", "æœŸé–“6ãƒ¶æœˆ"],
        })
        # çµæœã¯ProblemType enumã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        assert result["problem_type"] in [
            ProblemType.TRADE_OFF,
            ProblemType.RESOURCE_ALLOCATION,
        ]
        assert result["essence"]
        assert len(result["immutable_constraints"]) > 0

    @pytest.mark.asyncio
    async def test_analyze_timing(self, agent: DaoAgent) -> None:
        """ã‚¿ã‚¤ãƒŸãƒ³ã‚°å•é¡Œã®åˆ†æ."""
        result = await agent.run({
            "question": "æ–°ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥ã¯ã„ã¤ç€æ‰‹ã™ã¹ãã‹",
            "constraints": [],
        })
        # çµæœã¯ProblemType enumã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        assert result["problem_type"] == ProblemType.TIMING_DECISION


class TestFaAgent:
    """FaAgentã®ãƒ†ã‚¹ãƒˆ."""

    @pytest.fixture
    def agent(self) -> FaAgent:
        """ãƒ†ã‚¹ãƒˆç”¨Agentã‚’ä½œæˆ."""
        return FaAgent()

    @pytest.fixture
    def dao_result(self) -> dict:
        """ãƒ†ã‚¹ãƒˆç”¨DaoOutput."""
        return DaoOutput(
            problem_type=ProblemType.TRADE_OFF,
            essence="è¤‡æ•°ã®é¸æŠè‚¢é–“ã®æœ€é©ãªãƒãƒ©ãƒ³ã‚¹åˆ¤æ–­",
            immutable_constraints=["äºˆç®—1å„„å††", "æœŸé–“6ãƒ¶æœˆ"],
            hidden_assumptions=["å¸‚å ´ç’°å¢ƒãŒç¶™ç¶šã™ã‚‹"],
        ).model_dump()

    @pytest.mark.asyncio
    async def test_generate_paths(self, agent: FaAgent, dao_result: dict) -> None:
        """æˆ¦ç•¥ãƒ‘ã‚¹ã®ç”Ÿæˆ."""
        result = await agent.run({
            "dao_result": dao_result,
            "available_resources": {"budget": 10000},
            "time_horizon": "6ãƒ¶æœˆ",
        })
        assert len(result["recommended_paths"]) >= 1
        assert len(result["recommended_paths"]) <= 2  # æœ€å¤§2å€‹
        assert len(result["rejected_paths"]) >= 1  # ä¸æ¨å¥¨å¿…é ˆ
        assert len(result["decision_criteria"]) > 0


class TestShuAgent:
    """ShuAgentã®ãƒ†ã‚¹ãƒˆ."""

    @pytest.fixture
    def agent(self) -> ShuAgent:
        """ãƒ†ã‚¹ãƒˆç”¨Agentã‚’ä½œæˆ."""
        return ShuAgent()

    @pytest.fixture
    def fa_result(self) -> dict:
        """ãƒ†ã‚¹ãƒˆç”¨FaOutput."""
        return FaOutput(
            recommended_paths=[{
                "path_id": "A",
                "name": "æ¨å¥¨æ¡ˆA",
                "description": "æ®µéšçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
                "pros": ["ãƒªã‚¹ã‚¯ä½æ¸›"],
                "cons": ["æ™‚é–“ãŒã‹ã‹ã‚‹"],
                "success_probability": 0.7,
            }],
            rejected_paths=[],
            decision_criteria=["ãƒªã‚¹ã‚¯å¯¾ãƒªã‚¿ãƒ¼ãƒ³"],
        ).model_dump()

    @pytest.mark.asyncio
    async def test_generate_phases(self, agent: ShuAgent, fa_result: dict) -> None:
        """ãƒ•ã‚§ãƒ¼ã‚ºã®ç”Ÿæˆ."""
        result = await agent.run({
            "fa_result": fa_result,
            "selected_path_id": "A",
        })
        assert 3 <= len(result["phases"]) <= 5
        assert result["first_action"]
        assert len(result["dependencies"]) > 0


class TestQiAgent:
    """QiAgentã®ãƒ†ã‚¹ãƒˆ."""

    @pytest.fixture
    def agent(self) -> QiAgent:
        """ãƒ†ã‚¹ãƒˆç”¨Agentã‚’ä½œæˆ."""
        return QiAgent()

    @pytest.fixture
    def shu_result(self) -> dict:
        """ãƒ†ã‚¹ãƒˆç”¨ShuOutputï¼ˆæœ€ä½3ãƒ•ã‚§ãƒ¼ã‚ºå¿…è¦ï¼‰."""
        return ShuOutput(
            phases=[
                {
                    "phase_number": 1,
                    "name": "æº–å‚™",
                    "duration": "2é€±é–“",
                    "actions": ["ãƒãƒ¼ãƒ ç·¨æˆ"],
                    "deliverables": ["è¨ˆç”»æ›¸"],
                    "success_criteria": ["æ‰¿èª"],
                },
                {
                    "phase_number": 2,
                    "name": "å®Ÿè¡Œ",
                    "duration": "1ãƒ¶æœˆ",
                    "actions": ["é–‹ç™º"],
                    "deliverables": ["æˆæœç‰©"],
                    "success_criteria": ["å®Œäº†"],
                },
                {
                    "phase_number": 3,
                    "name": "è©•ä¾¡",
                    "duration": "1é€±é–“",
                    "actions": ["ãƒ¬ãƒ“ãƒ¥ãƒ¼"],
                    "deliverables": ["å ±å‘Šæ›¸"],
                    "success_criteria": ["æ‰¿èª"],
                },
            ],
            first_action="ã‚­ãƒƒã‚¯ã‚ªãƒ•MTG",
            dependencies=["çµŒå–¶æ‰¿èª"],
        ).model_dump()

    @pytest.mark.asyncio
    async def test_generate_implementations(self, agent: QiAgent, shu_result: dict) -> None:
        """å®Ÿè£…è¦ç´ ã®ç”Ÿæˆ."""
        result = await agent.run({
            "shu_result": shu_result,
            "tech_constraints": ["Pythonä½¿ç”¨"],
        })
        assert len(result["implementations"]) > 0
        assert len(result["tool_recommendations"]) > 0


class TestReviewAgent:
    """ReviewAgentã®ãƒ†ã‚¹ãƒˆ."""

    @pytest.fixture
    def agent(self) -> ReviewAgent:
        """ãƒ†ã‚¹ãƒˆç”¨Agentã‚’ä½œæˆ."""
        return ReviewAgent()

    @pytest.fixture
    def full_input(self) -> dict:
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ•ãƒ«å…¥åŠ›ï¼ˆShuOutputã¯æœ€ä½3ãƒ•ã‚§ãƒ¼ã‚ºå¿…è¦ï¼‰."""
        return {
            "dao_result": DaoOutput(
                problem_type=ProblemType.TRADE_OFF,
                essence="ãƒ†ã‚¹ãƒˆæœ¬è³ª",
                immutable_constraints=["åˆ¶ç´„1"],
                hidden_assumptions=["å‰æ1"],
            ).model_dump(),
            "fa_result": FaOutput(
                recommended_paths=[{
                    "path_id": "A",
                    "name": "æ¨å¥¨æ¡ˆA",
                    "description": "èª¬æ˜",
                    "pros": ["ãƒ¡ãƒªãƒƒãƒˆ"],
                    "cons": ["ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ"],
                    "success_probability": 0.7,
                }],
                rejected_paths=[],
                decision_criteria=["åŸºæº–1"],
            ).model_dump(),
            "shu_result": ShuOutput(
                phases=[
                    {
                        "phase_number": 1,
                        "name": "æº–å‚™",
                        "duration": "2é€±é–“",
                        "actions": ["è¡Œå‹•1"],
                        "deliverables": ["æˆæœç‰©1"],
                        "success_criteria": ["æ¡ä»¶1"],
                    },
                    {
                        "phase_number": 2,
                        "name": "å®Ÿè¡Œ",
                        "duration": "1ãƒ¶æœˆ",
                        "actions": ["è¡Œå‹•2"],
                        "deliverables": ["æˆæœç‰©2"],
                        "success_criteria": ["æ¡ä»¶2"],
                    },
                    {
                        "phase_number": 3,
                        "name": "è©•ä¾¡",
                        "duration": "1é€±é–“",
                        "actions": ["è¡Œå‹•3"],
                        "deliverables": ["æˆæœç‰©3"],
                        "success_criteria": ["æ¡ä»¶3"],
                    },
                ],
                first_action="æœ€åˆã®ä¸€æ­©",
                dependencies=["ä¾å­˜1"],
            ).model_dump(),
            "qi_result": {
                "implementations": [],
                "tool_recommendations": [],
                "integration_points": [],
                "technical_debt_warnings": [],
            },
        }

    @pytest.mark.asyncio
    async def test_review_pass(self, agent: ReviewAgent, full_input: dict) -> None:
        """æ­£å¸¸ã‚±ãƒ¼ã‚¹ã¯PASS."""
        result = await agent.run(full_input)
        assert result["overall_verdict"] in [
            ReviewVerdict.PASS.value,
            ReviewVerdict.REVISE.value,
        ]
        assert "confidence_score" in result


class TestDecisionEngine:
    """DecisionEngineã®ãƒ†ã‚¹ãƒˆ."""

    @pytest.fixture
    def engine(self) -> DecisionEngine:
        """ãƒ†ã‚¹ãƒˆç”¨Engineã‚’ä½œæˆ."""
        return DecisionEngine()

    @pytest.mark.asyncio
    async def test_reject_invalid_question(self, engine: DecisionEngine) -> None:
        """ä¸é©æ ¼ãªè³ªå•ã¯æ‹’å¦ã•ã‚Œã‚‹ï¼ˆCognitiveGateã¾ãŸã¯Gatekeeperã§ï¼‰."""
        # DecisionRequestã¯æœ€ä½10æ–‡å­—å¿…è¦ãªã®ã§ã€é•·ã‚ã®ä¸é©æ ¼è³ªå•ã‚’ä½¿ç”¨
        result = await engine.run({"question": "ä»Šæ—¥ã®å¤©æ°—ã¯ã©ã†ã§ã™ã‹ï¼Ÿæ•™ãˆã¦ãã ã•ã„"})
        # çµæœãŒdictã®å ´åˆï¼ˆæ‹’å¦æ™‚ï¼‰
        if isinstance(result, dict):
            # CognitiveGateã¾ãŸã¯Gatekeeperã§æ‹’å¦ã•ã‚Œã‚‹
            assert result.get("status") in ["rejected", "cognitive_gate_blocked"]
        else:
            # DecisionReportã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆï¼ˆå‡¦ç†ã•ã‚ŒãŸå ´åˆï¼‰
            assert hasattr(result, "report_id")

    @pytest.mark.asyncio
    async def test_process_valid_question(self, engine: DecisionEngine) -> None:
        """é©æ ¼ãªè³ªå•ã¯å‡¦ç†ã•ã‚Œã‚‹."""
        result = await engine.run({"question": "æ–°è¦äº‹æ¥­Aã¨Bã®ã©ã¡ã‚‰ã«æŠ•è³‡ã™ã¹ãã‹åˆ¤æ–­ã—ãŸã„"})
        # çµæœãŒdictã®å ´åˆï¼ˆæ‹’å¦æ™‚ï¼‰
        if isinstance(result, dict):
            assert result.get("status") == "rejected"
        else:
            # DecisionReportã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
            assert hasattr(result, "report_id")

    @pytest.mark.asyncio
    async def test_process_with_request_object(self, engine: DecisionEngine) -> None:
        """DecisionRequestã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã®å‡¦ç†."""
        request = DecisionRequest(
            question="ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã®æœ€é©åŒ–ã«ã¤ã„ã¦åˆ¤æ–­ã—ãŸã„",
            constraints=ConstraintSet(),
        )
        result = await engine.run({"question": request.question})
        # çµæœãŒdictã®å ´åˆï¼ˆæ‹’å¦æ™‚ï¼‰
        if isinstance(result, dict):
            assert "status" in result
        else:
            # DecisionReportã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
            assert hasattr(result, "report_id")


class TestUIComponents:
    """A2UI ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ“ãƒ«ãƒ€ãƒ¼ã®ãƒ†ã‚¹ãƒˆ."""

    @pytest.fixture
    def sample_report(self) -> DecisionReport:
        """ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ."""
        return DecisionReport(
            report_id="TEST-001",
            dao={
                "problem_type": "TRADE_OFF",
                "essence": "ãƒ†ã‚¹ãƒˆæœ¬è³ª",
                "immutable_constraints": ["åˆ¶ç´„1"],
                "hidden_assumptions": ["å‰æ1"],
            },
            fa={
                "recommended_paths": [{
                    "path_id": "A",
                    "name": "æ¡ˆA",
                    "description": "èª¬æ˜",
                    "pros": ["ãƒ¡ãƒªãƒƒãƒˆ"],
                    "cons": ["ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ"],
                    "success_probability": 0.8,
                }],
                "rejected_paths": [],
                "decision_criteria": ["åŸºæº–1"],
            },
            shu={
                "phases": [
                    {"phase_number": 1, "name": "æº–å‚™", "duration": "2é€±é–“", "actions": ["è¡Œå‹•1"], "deliverables": ["æˆæœç‰©"], "success_criteria": ["æ¡ä»¶"]},
                    {"phase_number": 2, "name": "å®Ÿè¡Œ", "duration": "1ãƒ¶æœˆ", "actions": ["è¡Œå‹•2"], "deliverables": ["æˆæœç‰©2"], "success_criteria": ["æ¡ä»¶2"]},
                    {"phase_number": 3, "name": "è©•ä¾¡", "duration": "1é€±é–“", "actions": ["è¡Œå‹•3"], "deliverables": ["æˆæœç‰©3"], "success_criteria": ["æ¡ä»¶3"]},
                ],
                "first_action": "MTG",
                "dependencies": [],
            },
            qi={
                "implementations": [{
                    "component": "API",
                    "technology": "FastAPI",
                    "estimated_effort": "1äººæœˆ",
                    "risks": [],
                }],
                "tool_recommendations": ["Jira"],
                "integration_points": [],
                "technical_debt_warnings": [],
            },
            review={"overall_verdict": "PASS", "confidence_score": 0.9, "findings": []},
            executive_summary=ExecutiveSummary(
                one_line_decision="æ¡ˆAã‚’é¸æŠ",
                recommended_action="å®Ÿè¡Œé–‹å§‹",
                key_risks=["ãƒªã‚¹ã‚¯1"],
                first_step="MTGè¨­å®š",
                estimated_impact="åŠ¹æœè¦‹è¾¼ã¿",
            ),
        )

    def test_build_report_view(self, sample_report: DecisionReport) -> None:
        """ãƒ¬ãƒãƒ¼ãƒˆãƒ“ãƒ¥ãƒ¼æ§‹ç¯‰ãƒ†ã‚¹ãƒˆ."""
        builder = DecisionUIComponentBuilder()
        components = builder.build_report_view(sample_report)
        assert len(components) >= 6
        assert components[0].props.get("title") == "ğŸ“Š ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼"


class TestPDFGenerator:
    """PDFç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚¹ãƒˆ."""

    @pytest.fixture
    def sample_report(self) -> DecisionReport:
        """ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ."""
        return DecisionReport(
            report_id="PDF-TEST-001",
            dao={
                "problem_type": "TRADE_OFF",
                "essence": "PDFæœ¬è³ª",
                "immutable_constraints": [],
                "hidden_assumptions": [],
            },
            fa={
                "recommended_paths": [{
                    "path_id": "A",
                    "name": "æ¡ˆA",
                    "description": "èª¬æ˜",
                    "pros": [],
                    "cons": [],
                    "success_probability": 0.7,
                }],
                "rejected_paths": [],
                "decision_criteria": [],
            },
            shu={
                "phases": [
                    {"phase_number": 1, "name": "æº–å‚™", "duration": "2é€±é–“", "actions": [], "deliverables": [], "success_criteria": []},
                    {"phase_number": 2, "name": "å®Ÿè¡Œ", "duration": "1ãƒ¶æœˆ", "actions": [], "deliverables": [], "success_criteria": []},
                    {"phase_number": 3, "name": "è©•ä¾¡", "duration": "1é€±é–“", "actions": [], "deliverables": [], "success_criteria": []},
                ],
                "first_action": "MTG",
                "dependencies": [],
            },
            qi={
                "implementations": [],
                "tool_recommendations": [],
                "integration_points": [],
                "technical_debt_warnings": [],
            },
            review={"overall_verdict": "PASS", "confidence_score": 0.85, "findings": []},
            executive_summary=ExecutiveSummary(
                one_line_decision="æ¡ˆAã‚’é¸æŠ",
                recommended_action="å®Ÿè¡Œ",
                key_risks=[],
                first_step="MTG",
                estimated_impact="åŠ¹æœ",
            ),
        )

    def test_generate_pdf_fallback(self, sample_report: DecisionReport) -> None:
        """PDFç”Ÿæˆãƒ†ã‚¹ãƒˆï¼ˆHTMLãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰."""
        generator = PDFGeneratorService()
        result = generator.generate_pdf(sample_report)
        assert len(result) > 0
        if not generator._has_reportlab:
            assert b"<html" in result or b"<!DOCTYPE" in result
