æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¾ã™ã€‚

## ğŸš€ æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã®æ‰‹é †

### 1. **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ã¨é…å¸ƒ**

````toml path=pyproject.toml mode=EDIT
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "ai-blocks"
version = "0.1.0"
dynamic = ["readme"]
````

````makefile path=Makefile mode=EDIT
# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
build:
	python -m build

# PyPIã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ†ã‚¹ãƒˆç’°å¢ƒï¼‰
upload-test:
	python -m twine upload --repository testpypi dist/*

# PyPIã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæœ¬ç•ªç’°å¢ƒï¼‰
upload:
	python -m twine upload dist/*

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
clean:
	rm -rf build/ dist/ *.egg-info/
````

### 2. **æœ¬ç•ªç”¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•**

```bash
# æœ¬ç•ªç’°å¢ƒã§ã®æ¨™æº–ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install ai-blocks

# ç‰¹å®šæ©Ÿèƒ½ä»˜ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install ai-blocks[llm]
pip install ai-blocks[vector]
pip install ai-blocks[all]

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³æŒ‡å®šã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install ai-blocks==0.1.0
```

### 3. **DockeråŒ–ã«ã‚ˆã‚‹æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤**

````dockerfile path=Dockerfile mode=EDIT
FROM python:3.11-slim

WORKDIR /app

# ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Pythonä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã®ã‚³ãƒ”ãƒ¼
COPY . .

# æœ¬ç•ªç”¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN pip install .

# érootãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆ
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

EXPOSE 8000

CMD ["python", "-m", "ai_blocks.server"]
````

````yaml path=docker-compose.prod.yml mode=EDIT
version: '3.8'

services:
  ai-blocks:
    build: .
    ports:
      - "8000:8000"
    environment:
      - AI_BLOCKS_ENV=production
      - AI_BLOCKS_LOG_LEVEL=INFO
      - AI_BLOCKS_OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./data:/app/data
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

volumes:
  redis_data:
````

### 4. **CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š**

````yaml path=.github/workflows/release.yml mode=EDIT
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install -e ".[dev]"

    - name: Run tests
      run: |
        pytest tests/ --cov=ai_blocks --cov-report=xml

    - name: Type check
      run: mypy ai_blocks/

  build-and-publish:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install build tools
      run: |
        pip install build twine

    - name: Build package
      run: python -m build

    - name: Publish to PyPI
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
      run: twine upload dist/*

  docker-build:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to DockerHub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}

    - name: Build and push
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: |
          aiblocks/ai-blocks:latest
          aiblocks/ai-blocks:${{ github.ref_name }}
````

### 5. **æœ¬ç•ªç’°å¢ƒè¨­å®š**

````python path=ai_blocks/config/production.py mode=EDIT
from .settings import Settings
from typing import Optional

class ProductionSettings(Settings):
    """æœ¬ç•ªç’°å¢ƒç”¨è¨­å®š"""

    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–
    debug: bool = False
    log_level: str = "INFO"

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
    enable_caching: bool = True
    cache_ttl: int = 3600
    max_concurrent_requests: int = 100

    # ç›£è¦–è¨­å®š
    enable_metrics: bool = True
    enable_tracing: bool = True

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
    database_url: Optional[str] = None
    redis_url: Optional[str] = None

    class Config:
        env_file = ".env.production"
        env_prefix = "AI_BLOCKS_"

def get_production_settings() -> ProductionSettings:
    return ProductionSettings()
````

### 6. **ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥ã®å®Ÿè£…**

````python path=ai_blocks/core/registry.py mode=EXCERPT
async def deploy_version(
    self,
    component_type: str,
    component_name: str,
    target_version: str,
    strategy: Optional[DeploymentStrategy] = None,
    canary_percentage: float = 0.1
) -> bool:
    """æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹"""
    # ... ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥ã®å®Ÿè£…
````

### 7. **æœ¬ç•ªç›£è¦–ã¨ãƒ­ã‚°è¨­å®š**

````python path=ai_blocks/observability/production.py mode=EDIT
import logging
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

def setup_production_logging():
    """æœ¬ç•ªç’°å¢ƒç”¨ãƒ­ã‚°è¨­å®š"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('/var/log/ai-blocks/app.log')
        ]
    )

def setup_production_tracing():
    """æœ¬ç•ªç’°å¢ƒç”¨ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°è¨­å®š"""
    jaeger_exporter = JaegerExporter(
        agent_host_name="jaeger",
        agent_port=6831,
    )

    trace.set_tracer_provider(TracerProvider())
    span_processor = BatchSpanProcessor(jaeger_exporter)
    trace.get_tracer_provider().add_span_processor(span_processor)
````

## ğŸ”§ æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. **ç’°å¢ƒå¤‰æ•°ç®¡ç†**
```bash
# .env.production
AI_BLOCKS_ENV=production
AI_BLOCKS_DEBUG=false
AI_BLOCKS_LOG_LEVEL=INFO
AI_BLOCKS_OPENAI_API_KEY=your_production_key
AI_BLOCKS_DATABASE_URL=postgresql://user:pass@db:5432/aiblocks
AI_BLOCKS_REDIS_URL=redis://redis:6379/0
```

### 2. **ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè£…**
````python path=ai_blocks/health.py mode=EDIT
from fastapi import FastAPI
from pydantic import BaseModel

class HealthResponse(BaseModel):
    status: str
    version: str
    timestamp: str

app = FastAPI()

@app.get("/health", response_model=HealthResponse)
async def health_check():
    return HealthResponse(
        status="healthy",
        version="0.1.0",
        timestamp=datetime.now().isoformat()
    )
````

### 3. **ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚³ãƒãƒ³ãƒ‰**
```bash
# 1. ã‚¿ã‚°ä½œæˆã¨ãƒ—ãƒƒã‚·ãƒ¥
git tag v0.1.0
git push origin v0.1.0

# 2. Dockeræœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤
docker-compose -f docker-compose.prod.yml up -d

# 3. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:8000/health

# 4. ãƒ­ã‚°ç¢ºèª
docker-compose -f docker-compose.prod.yml logs -f ai-blocks
```

ã“ã®æ§‹æˆã«ã‚ˆã‚Šã€å®‰å…¨ã§åŠ¹ç‡çš„ãªæœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ãŒå®Ÿç¾ã§ãã¾ã™ã€‚
